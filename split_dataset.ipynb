{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict as ddict\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = '../WN18RR'\n",
    "# data_path = '../FB15K237'\n",
    "data_path = '../NELL-995'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent2id_file = open(os.path.join(data_path, 'entity2id.txt'))\n",
    "ent2id = dict()\n",
    "num_ent = int(ent2id_file.readline())\n",
    "for line in ent2id_file.readlines():\n",
    "    ent, idx = line.split()\n",
    "    ent2id[ent] = int(idx)\n",
    "id2ent = {v: k for k, v in ent2id.items()}\n",
    "    \n",
    "rel2id = dict()\n",
    "rel2id_file = open(os.path.join(data_path, 'relation2id.txt'))\n",
    "num_rel = int(rel2id_file.readline())\n",
    "for line in rel2id_file.readlines():\n",
    "    rel, idx = line.split()\n",
    "    rel2id[rel] = int(idx)\n",
    "id2rel = {v: k for k, v in rel2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = []\n",
    "\n",
    "train2id_file = open(os.path.join(data_path, 'train2id.txt'))\n",
    "num_train = int(train2id_file.readline())\n",
    "train_triples = []\n",
    "for line in train2id_file.readlines():\n",
    "    line = map(lambda x: int(x), line.split())\n",
    "    h, t, r = line\n",
    "    triples.append([h, r, t])\n",
    "    train_triples.append([h, r, t])\n",
    "\n",
    "valid2id_file = open(os.path.join(data_path, 'valid2id.txt'))\n",
    "num_valid = int(valid2id_file.readline())\n",
    "valid_triples = []\n",
    "for line in valid2id_file.readlines():\n",
    "    line = map(lambda x: int(x), line.split())\n",
    "    h, t, r = line\n",
    "    triples.append([h, r, t])\n",
    "    valid_triples.append([h, r, t])\n",
    "\n",
    "test2id_file = open(os.path.join(data_path, 'test2id.txt'))\n",
    "num_test = int(test2id_file.readline())\n",
    "test_triples = []\n",
    "for line in test2id_file.readlines():\n",
    "    line = map(lambda x: int(x), line.split())\n",
    "    h, t, r = line\n",
    "    triples.append([h, r, t])\n",
    "    test_triples.append([h, r, t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = np.array(triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random split relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_client = 3\n",
    "rel_pool = np.unique(triples[:,1])\n",
    "\n",
    "client_rel = []\n",
    "num_client_rel = round(len(rel_pool) / num_client)\n",
    "\n",
    "for i in range(num_client):\n",
    "    client_rel.append([])\n",
    "    if i != num_client - 1:\n",
    "        client_rel[i] = (np.random.choice(rel_pool, num_client_rel, replace=False))\n",
    "        rel_pool = np.setdiff1d(rel_pool, client_rel, assume_unique=True)\n",
    "    else:\n",
    "        client_rel[i] = rel_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split triples into client by relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_triples = [[] for i in range(num_client)]\n",
    "\n",
    "for tri in triples.tolist():\n",
    "    h, r, t = tri\n",
    "    for i in range(num_client):\n",
    "        if r in client_rel[i]:\n",
    "            client_triples[i].append(tri)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split train/valid/test in client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n"
     ]
    }
   ],
   "source": [
    "client_data = []\n",
    "\n",
    "for client_idx in tqdm(range(num_client)):\n",
    "    all_triples = client_triples[client_idx]\n",
    "\n",
    "    triples_reidx = []\n",
    "    ent_reidx = dict()\n",
    "    rel_reidx = dict()\n",
    "    entidx = 0\n",
    "    relidx = 0\n",
    "\n",
    "    ent_freq = ddict(int)\n",
    "    rel_freq = ddict(int)\n",
    "\n",
    "    for tri in all_triples:\n",
    "        h, r, t = tri\n",
    "        ent_freq[h] += 1\n",
    "        ent_freq[t] += 1\n",
    "        rel_freq[r] += 1\n",
    "        if h not in ent_reidx.keys():\n",
    "            ent_reidx[h] = entidx\n",
    "            entidx += 1\n",
    "        if t not in ent_reidx.keys():\n",
    "            ent_reidx[t] = entidx\n",
    "            entidx += 1\n",
    "        if r not in rel_reidx.keys():\n",
    "            rel_reidx[r] = relidx\n",
    "            relidx += 1\n",
    "        triples_reidx.append([h, r, t, ent_reidx[h], rel_reidx[r], ent_reidx[t]])\n",
    "\n",
    "    client_train_triples = []\n",
    "    client_valid_triples = []\n",
    "    client_test_triples = []\n",
    "\n",
    "    random.shuffle(triples_reidx)\n",
    "    for idx, tri in enumerate(triples_reidx):\n",
    "        h, r, t, _, _, _ = tri\n",
    "        if ent_freq[h] > 2 and ent_freq[t] > 2 and rel_freq[r] > 2:\n",
    "            client_test_triples.append(tri)\n",
    "            ent_freq[h] -= 1\n",
    "            ent_freq[t] -= 1\n",
    "            rel_freq[r] -= 1\n",
    "        else:\n",
    "            client_train_triples.append(tri)\n",
    "        if len(client_test_triples) > int(len(triples_reidx) * 0.2):\n",
    "            break\n",
    "    client_train_triples.extend(triples_reidx[idx+1:])\n",
    "\n",
    "    random.shuffle(client_test_triples)\n",
    "    test_len = len(client_test_triples)\n",
    "    client_valid_triples = client_test_triples[:int(test_len/2)]\n",
    "    client_test_triples = client_test_triples[int(test_len/2):] \n",
    "\n",
    "    train_edge_index_ori = np.array(client_train_triples)[:, [0, 2]].T\n",
    "    train_edge_type_ori = np.array(client_train_triples)[:, 1].T\n",
    "    train_edge_index = np.array(client_train_triples)[:, [3, 5]].T\n",
    "    train_edge_type = np.array(client_train_triples)[:, 4].T\n",
    "\n",
    "    valid_edge_index_ori = np.array(client_valid_triples)[:, [0, 2]].T\n",
    "    valid_edge_type_ori = np.array(client_valid_triples)[:, 1].T\n",
    "    valid_edge_index = np.array(client_valid_triples)[:, [3, 5]].T\n",
    "    valid_edge_type = np.array(client_valid_triples)[:, 4].T\n",
    "\n",
    "    test_edge_index_ori = np.array(client_test_triples)[:, [0, 2]].T\n",
    "    test_edge_type_ori = np.array(client_test_triples)[:, 1].T\n",
    "    test_edge_index = np.array(client_test_triples)[:, [3, 5]].T\n",
    "    test_edge_type = np.array(client_test_triples)[:, 4].T\n",
    "\n",
    "    client_data_dict = {'train': {'edge_index': train_edge_index, 'edge_type': train_edge_type, \n",
    "                          'edge_index_ori': train_edge_index_ori, 'edge_type_ori': train_edge_type_ori},\n",
    "                'test': {'edge_index': test_edge_index, 'edge_type': test_edge_type, \n",
    "                         'edge_index_ori': test_edge_index_ori, 'edge_type_ori': test_edge_type_ori},\n",
    "                'valid': {'edge_index': valid_edge_index, 'edge_type': valid_edge_type, \n",
    "                      'edge_index_ori': valid_edge_index_ori, 'edge_type_ori': valid_edge_type_ori}}\n",
    "\n",
    "    client_data.append(client_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(client_data, open('test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
